# -*- coding: utf-8 -*-
"""MINI2_SUAP_MODELO_5A_COM_ARVORE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13cmNbnwNZFt4uV2GV8bJ7oXoQZfwJ_uW

# dados SUAP
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn import svm


from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import VotingClassifier

data = pd.read_excel("C:/Users/Sander/Documents/exe_IA1/IA1_Semana9_exe/modeloR_python_projeto2/TCC_CODIGO/opcao2_ao_testar_sempre_nao_evade/modeloTCC_Arvore2_ComAtributo_Sexo_SemFreq_SemAuxilio/Relatorio.xls")
#data = pd.read_excel("/content/drive/MyDrive/MODELO_ML_CLASSIFICACAO_TCC_2023_2024/ATRIBUTOS_E_MODELOS_ARTIGOS_SELECIONADOS/MODELO_1_KAGGLE_SUGERIDO_PROFESSOR/MODELO_COM_BASE_REAL_1/MODELO_BASE_SUAP_VERSAO_2_3/Relatorio.xls")
#data.head()

data.info()

data2 = data
data2.info()

data2.isnull().sum()/len(data2)*100

"""VERIFICAR SE EXISTE '-' NOS REGISTROS E ANALISAR SITUAÇÃO EM CASO POSITIVO"""

for coluna in data2.columns:
  numero_registros_com_hifen = 0
  for valor in data2[coluna]:
    if type(valor) == str and "-" in valor:
      numero_registros_com_hifen += 1
  if numero_registros_com_hifen > 0:
    print(f"Coluna: {coluna}")
    print(f"Número de registros com '-': {numero_registros_com_hifen}")

"""**O PRÓXIMO PASSO, APÓS O CARREGAMENTO E VISUALIZAÇÃO DOS DADOS, IDENTIFICAÇÃO DOS VALORES NULOS, DOS ATRIBUTOS COM 'STRINGS' INDESEJÁVEIS COMO '-' E SUAS QUANTIDADES, UMA VEZ DEFINIDO QUAIS ATRIBUTOS SERÃO USADOS, INICIA-SE A CORREÇÃO E AJUSTE DOS DADOS PARA CONSTRUÇÃO DO MODELO**

ESCOLHENDO ATRIBUTOS por inferencia:

DICIONÁRIO DE DADOS

Estado civil:0/1 (Solteiro/Nao Solteiro)-
Sexo: 0/1 ('F', 'M')-
Etnia/Raca:0/1 (bca, nao bca)-
Acesso a internet: 0/1 (Acesso no computador em minha própria casa: Contrario)-
Tipo origem:0/1 (privada, nao privada)-
Forma ingresso:0/1 (ampla, nao ampla concorrencia)-
Situação no curso: Target:0/1 (evade, nao evade)-
Situação periodo:0/1 (evade, nao evade)-
Frequência no Período: 0-100-
Atividade Complementares Pendentes (Sim:0/ outros:1)-
Carga Horaria de TCC pendentes (Sim:0/outros 1)-
Necessidade de auxilio estudantil: Consigo me manter independentemente de auxílios da instituição": 0, outros 1
"""

base = data2[['Etnia/Raça', 'Estado Civil', 'Sexo','Acesso à Internet','Forma de Ingresso', 'Situação no Curso']]
#acuracia: +/- 85%

"""**Para atributos com '-' distribuir randomicamnte atribuições 0 ou 1: 50% dos dados receberá 0, demais 1 **"""

base.head()

#Colunas que serão preenchidas com 0 ou 1
colunas_a_preencher = base.select_dtypes(include=['object']).columns

# Verificando se há registros com "-" em cada coluna
for coluna in colunas_a_preencher:
    #Encontrando os índices das linhas com "-"
    indices_com_menos = base[coluna] == "-"

    # Se houver registros com "-", preencha-os com 0 ou 1 aleatoriamente
    if indices_com_menos.any():
      numero_de_linhas_com_menos = indices_com_menos.sum()
      valores_aleatorios = np.random.choice([0, 1], size=numero_de_linhas_com_menos)
      base.loc[indices_com_menos, coluna] = valores_aleatorios

base.head()

# Definindo os dicionários com a lógica (0/1)

acesso_internet = {"Acesso no computador em minha própria casa": 0}
estado_civil = {"Solteiro": 0}
sexo = {"F": 0}
#acc_pendente = {"Sim": 0}
#carga_horaria_tcc_pendente = {"Sim": 0}
#
etnia_map = {"Branca": 0}
#necessidade_auxilio_map = {"Consigo me manter independentemente de auxílios da instituição": 0}
situacao_curso_map = {"Evasão": 0}
#situacao_periodo_map = {"Evasão": 0}
#tipo_origem_map = {"Privada": 0}
forma_ingresso_map = {"Ampla concorrência": 0}

# Substituindo os valores no DataFrame

base["Acesso à Internet"] = base["Acesso à Internet"].replace(acesso_internet)
base["Estado Civil"] = base["Estado Civil"].replace(estado_civil)
base["Sexo"] = base["Sexo"].replace(sexo)
#base["Atividades Complementares Pendente"] = base["Atividades Complementares Pendente"].replace(acc_pendente)
#base["Carga Horária de TCC Pendente"] = base["Carga Horária de TCC Pendente"].replace(carga_horaria_tcc_pendente)
#
base["Etnia/Raça"] = base["Etnia/Raça"].replace(etnia_map)
#base["Necessidade de Auxílio Estudantil"] = base["Necessidade de Auxílio Estudantil"].replace(necessidade_auxilio_map)
base["Situação no Curso"] = base["Situação no Curso"].replace(situacao_curso_map)
#base["Situação no Período"] = base["Situação no Período"].replace(situacao_periodo_map)
#base["Tipo de Escola de Origem"] = base["Tipo de Escola de Origem"].replace(tipo_origem_map)
base["Forma de Ingresso"] = base["Forma de Ingresso"].replace(forma_ingresso_map)

base.head()

#Atualizando os demais valores para 1

base.loc[base["Acesso à Internet"] != 0, "Acesso à Internet"] = 1
base.loc[base["Estado Civil"] != 0, "Estado Civil"] = 1
base.loc[base["Sexo"] != 0, "Sexo"] = 1
#base.loc[base["Atividades Complementares Pendente"] != 0, "Atividades Complementares Pendente"] = 1
#base.loc[base["Carga Horária de TCC Pendente"] != 0, "Carga Horária de TCC Pendente"] = 1
#
#
base.loc[base["Etnia/Raça"] != 0, "Etnia/Raça"] = 1
base.loc[base["Forma de Ingresso"] != 0, "Forma de Ingresso"] = 1
#base.loc[base["Situação no Período"] != 0, "Situação no Período"] = 1
base.loc[base["Situação no Curso"] != 0, "Situação no Curso"] = 1
#base.loc[base["Tipo de Escola de Origem"] != 0, "Tipo de Escola de Origem"] = 1
#base.loc[base["Necessidade de Auxílio Estudantil"] != 0, "Necessidade de Auxílio Estudantil"] = 1

base.head()

# Verificando se o DataFrame contém valores negativos
if any(base[col].min() < 0 for col in base.columns):
    print("O DataFrame contém valores negativos.")
else:
    print("O DataFrame não contém valores negativos.")

base.info()

print(base["Situação no Curso"].unique())

base.corr()['Situação no Curso']

base['Situação no Curso'].value_counts()

x = base['Situação no Curso'].value_counts().index
y = base['Situação no Curso'].value_counts().values

df = pd.DataFrame({
    'Situação no Curso': x,
    'Count_T' : y
})

correlations = base.corr()['Situação no Curso']
top_14_features = correlations.abs().nlargest(14).index
top_14_corr_values = correlations[top_14_features]

def detect_outliers(data):
  outliers_dict = {}
  for col in data.columns:
    if data[col].dtype != object:  # Ignore non-numeric columns
      q1 = data[col].quantile(0.25)
      q3 = data[col].quantile(0.75)
      iqr = q3 - q1
      lower_bound = q1 - 1.5 * iqr
      upper_bound = q3 + 1.5 * iqr
      outliers_mask = (data[col] < lower_bound) | (data[col] > upper_bound)
      outliers = data[outliers_mask].index.tolist()
      outliers_dict[col] = len(outliers) if outliers else 0
  return outliers_dict

# Chamada da função
outliers_dict = detect_outliers(base)

# Verificação de outliers
total_outliers = sum(outliers_dict.values())

# Exibição dos resultados
if not total_outliers:
  print("Não foram encontrados outliers no DataFrame.")
else:
  print(f"Total de outliers encontrados: {total_outliers}")
  for col, count in outliers_dict.items():
    if count > 0:
      print(f"  * Coluna '{col}': {count} outliers")

"""**CONSTRUINDO O(S) MODELO(S)**"""

basef = base

basef.head()

# Salvando o DataFrame em um arquivo CSV
#basef.to_csv('basef.csv')

X = basef.drop(columns=['Situação no Curso'], axis=1)
X.info()

##X = new_data.drop('Target', axis=1)

# os labels: y
y = basef['Situação no Curso']
print(y)

print("Tipo de dados de X_train:", type(X))
print("Tipo de dados de y_train:", type(y))
print("Formato de X_train:", X.shape)
print("Formato de y_train:", y.shape)
#X = X.values
#y = y.values
y = np.array(y, dtype=int)

print(y)

# treinando os dados
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)
print(y_train)

dtree = DecisionTreeClassifier(random_state=0)

dtree.fit(X_train,y_train)

y_predTree = dtree.predict(X_test)
print("Accuracy :",round(accuracy_score(y_test,y_predTree)*100,2),"%")

# Acessando a importância das variáveis (ACRESCENTADO: 11 JUNH 2024)
# Em R, o pacote Caret
# avalia a importância das
# variáveis em modelos de classificação, fornecendo diversas métricas e métodos para quantificar a relevância de cada variável na predição da classe alvo
# usando função varImp() baseada na Permutação de Importância
# no Python, existe algo semelhante:
# Utilize a biblioteca scikit-learn e seus módulos:
# SelectFromModel: Para embrulhar o modelo e realizar a seleção de variáveis.
# permutation_importance: Para calcular a importância das variáveis por permutação.
# OBS: Como não consegui atualizar a biblioteca scikit-learn, irei utilzar uma abordagem mais simples, porém muito funcional:
# Todavia, a cada processamento, o percentual de relevancia do atributo do modelo varia bastante
# Nesse modelo, o que mais se destaca eh o Estado civil

# Acessando a importância das variáveis
importances = dtree.feature_importances_

# Imprimindo as variáveis mais importantes do modelo
sorted_idx = importances.argsort()[::-1]
print("Variáveis mais Importantes, em ordem descrecente:")
for i in range(5):
    print(f"{X.columns[sorted_idx[i]]}: {importances[sorted_idx[i]]}")

"""**TESTANDO COM INSERÇÃO DE DADOS**"""

import pickle #do professor: exporta modelo ml
labels_names = basef['Situação no Curso']
pickle.dump(labels_names, open('names.pkl','wb'))
nomesbase = pickle.load(open('names.pkl','rb'))
print(nomesbase)

basef.head(20)

"""ESCOLHENDO ATRIBUTOS por inferencia:

DICIONÁRIO DE DADOS

Estado civil:0/1 (Solteiro/Nao Solteiro)-
Sexo: 0/1 ('F', 'M')-
Etnia/Raca:0/1 (bca, nao bca)-
Acesso a internet: 0/1 (Acesso no computador em minha própria casa: Contrario)-
Tipo origem:0/1 (privada, nao privada)-
Forma ingresso:0/1 (ampla, nao ampla concorrencia)-
Situação no curso: Target:0/1 (evade, nao evade)-
Situação periodo:0/1 (evade, nao evade)-
Frequência no Período: 0-100-
Atividade Complementares Pendentes (Sim:0/ outros:1)-
Carga Horaria de TCC pendentes (Sim:0/outros 1)-
Necessidade de auxilio estudantil: Consigo me manter independentemente de auxílios da instituição": 0, outros 1

"""

pickle.dump(dtree, open('model.pkl','wb'))
model = pickle.load(open('model.pkl','rb'))

print (model.predict([ [0,	1,	1,	0,	1] ]))#1
print (model.predict([ [1,	1,	1,	1,	1] ]))#0
print (model.predict([ [0,	0,	1,	1,	1] ]))#0
print (model.predict([ [0,	1,	1,	0,	1] ]))#0

#acuracias variando entre 80-85%