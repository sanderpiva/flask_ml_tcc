# -*- coding: utf-8 -*-
"""ULTIMO_IRA_0_1_Novo_Evade_1_NaoEvade_0_ARVORE_SUAP_MODELO_5A_COM_ARVORE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tahgybZS77DznXCl0GczzT85AznCxpWu

# dados SUAP
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import VotingClassifier

#data = pd.read_excel("/content/Relatorio.xls")
data = pd.read_excel("C:/Users/Sander/Documents/modelo_final/Relatorio.xls")

data.head()

data.info()

data2 = data
data2.info()

data2.isnull().sum()/len(data2)*100

"""VERIFICAR SE EXISTE '-' NOS REGISTROS E ANALISAR SITUAÇÃO EM CASO POSITIVO"""

for coluna in data2.columns:
  numero_registros_com_hifen = 0
  for valor in data2[coluna]:
    if type(valor) == str and "-" in valor:
      numero_registros_com_hifen += 1
  if numero_registros_com_hifen > 0:
    print(f"Coluna: {coluna}")
    print(f"Número de registros com '-': {numero_registros_com_hifen}")

"""**O PRÓXIMO PASSO, APÓS O CARREGAMENTO E VISUALIZAÇÃO DOS DADOS, IDENTIFICAÇÃO DOS VALORES NULOS, DOS ATRIBUTOS COM 'STRINGS' INDESEJÁVEIS COMO '-' E SUAS QUANTIDADES, UMA VEZ DEFINIDO QUAIS ATRIBUTOS SERÃO USADOS, INICIA-SE A CORREÇÃO E AJUSTE DOS DADOS PARA CONSTRUÇÃO DO MODELO**

ESCOLHENDO ATRIBUTOS por inferencia: (Trabalhos relacionados analisados sugerem que variaveis explicativas de cunho socil, economico e desempenho podem ser relavantes ao modelo). Adaptando a ideia para os dados utilizados do IFSULDEMINAS Campus Machado

DICIONÁRIO DE DADOS

Estado civil: Nao Solteiro = 0/Solteiro = 1
Sexo: 'F' = 0, 'M' = 1
Etnia/Raca: nao bca = 0, bca = 1
Acesso a internet: Tenho acesso no computador em minha própria casa = 1, outros = 0
Tipo origem: nao privada = 0, privada = 1
Forma ingresso:
//
 "Ampla concorrência": 1,
  "Ampla concorrência (ENEM)": 1,
  "Ampla concorrência (SISU)": 1,
  "Ampla concorrência (Vestibular)": 1,
  demais considerar 0
//
Situação no curso: Target:(nao evade = 0 (Matriculado, Concluido, Formado), evade = 1)
I.R.A notas variando de 0 - 10
Frequência no Período: 0-100
Necessidade de auxilio estudantil:(Consigo me manter independentemente de auxílios da instituição = 0, ou seja, não preciso de auxilio/ Nao consigo me manter, preciso de auxilio ou outros correlatos = 1)
//
Carga horaria de seminario pendente: Sim:1 Nao:0
Carga horaria de Pratica profissional pendente: Sim:1 Nao:2
"""

###
# 73 - 79%
base = data2[['Acesso à Internet',
              'I.R.A.','Etnia/Raça',
              'Estado Civil','Tipo de Escola de Origem', 'Carga Horária de Prática Profissional Pendente',
              'Carga-Horária de Seminário Pendente',
              'Situação no Curso']]

"""**Para atributos com '-' distribuir randomicamnte atribuições 0 ou 1: 50% dos dados receberá 0, demais 1 **"""

base.head()

#Colunas que serão preenchidas com 0 ou 1
colunas_a_preencher = base.select_dtypes(include=['object']).columns

# Verificando se há registros com "-" em cada coluna
for coluna in colunas_a_preencher:
    #Encontrando os índices das linhas com "-"
    indices_com_menos = base[coluna] == "-"

    # Se houver registros com "-", preencha-os com 0 ou 1 aleatoriamente
    if indices_com_menos.any():
      numero_de_linhas_com_menos = indices_com_menos.sum()
      valores_aleatorios = np.random.choice([0, 1], size=numero_de_linhas_com_menos)
      base.loc[indices_com_menos, coluna] = valores_aleatorios

base.head()

# Definindo os dicionários com a lógica adaptada: evade:1 nao evade: 0

#
carga_hor_pratica_profiss_pend = {"Sim": 1}
carga_horaria_seminario_pend = {"Sim": 1}
acesso_internet = {"Acesso no computador em minha própria casa": 1}
estado_civil = {"Solteiro": 1}
etnia_map = {"Branca": 1}
situacao_curso_map = {
    "Matriculado": 0,
    "Formado": 0,
    "Concluído": 0
}

tipo_origem_map = {"Privada": 1}

# Substituindo os valores no DataFrame

#
base["Carga Horária de Prática Profissional Pendente"] = base["Carga Horária de Prática Profissional Pendente"].replace(carga_hor_pratica_profiss_pend)
base["Carga-Horária de Seminário Pendente"] = base["Carga-Horária de Seminário Pendente"].replace(carga_horaria_seminario_pend)
base["Acesso à Internet"] = base["Acesso à Internet"].replace(acesso_internet)
base["Estado Civil"] = base["Estado Civil"].replace(estado_civil)
base["Etnia/Raça"] = base["Etnia/Raça"].replace(etnia_map)
base["Situação no Curso"] = base["Situação no Curso"].replace(situacao_curso_map)
base["Tipo de Escola de Origem"] = base["Tipo de Escola de Origem"].replace(tipo_origem_map)

base.head()

#Atualizando os demais valores

base.loc[base["Acesso à Internet"] != 1, "Acesso à Internet"] = 0
base.loc[base["Estado Civil"] != 1, "Estado Civil"] = 0
base.loc[base["Carga Horária de Prática Profissional Pendente"] != 1, "Carga Horária de Prática Profissional Pendente"] = 0
base.loc[base["Carga-Horária de Seminário Pendente"] != 1, "Carga-Horária de Seminário Pendente"] = 0
base.loc[base["Etnia/Raça"] != 1, "Etnia/Raça"] = 0
base.loc[base["Situação no Curso"] != 0, "Situação no Curso"] = 1
base.loc[base["Tipo de Escola de Origem"] != 1, "Tipo de Escola de Origem"] = 0

base.head(20)

base.info()

print(base["Situação no Curso"].unique())

# Converte para string, substitui vírgulas por pontos e depois converte para float
base['I.R.A.'] = base['I.R.A.'].astype(str).str.replace(',', '.').astype(float)

# Conta o número de valores ausentes na coluna 'I.R.A.'
num_missing_values = base['I.R.A.'].isna().sum()
print(f'Número de valores ausentes em "I.R.A.": {num_missing_values}')

# Preenche valores ausentes da coluna 'I.R.A.' com zero
base['I.R.A.'] = base['I.R.A.'].fillna(0)

# Conta o número de valores ausentes na coluna 'I.R.A.'
num_missing_values = base['I.R.A.'].isna().sum()
print(f'Número de valores ausentes em "I.R.A.": {num_missing_values}')

# Converte para string, substitui vírgulas por pontos e depois converte para float
base['I.R.A.'] = base['I.R.A.'].astype(str).str.replace(',', '.').astype(float)

base['I.R.A.'] = base['I.R.A.'].apply(lambda x: 0 if x < 6 else 1)

"""**Transformação completa dos dados**"""

base.head()

"""**Após a transformação completa dos dados, checar se tem valor negativo decorrente de inserção indevida.**"""

"""**Correlação**"""

def detect_outliers(data):
  outliers_dict = {}
  for col in data.columns:
    if data[col].dtype != object:  # Ignore non-numeric columns
      q1 = data[col].quantile(0.25)
      q3 = data[col].quantile(0.75)
      iqr = q3 - q1
      lower_bound = q1 - 1.5 * iqr
      upper_bound = q3 + 1.5 * iqr
      outliers_mask = (data[col] < lower_bound) | (data[col] > upper_bound)
      outliers = data[outliers_mask].index.tolist()
      outliers_dict[col] = len(outliers) if outliers else 0
  return outliers_dict

# Chamada da função
outliers_dict = detect_outliers(base)

# Verificação de outliers
total_outliers = sum(outliers_dict.values())

# Exibição dos resultados
if not total_outliers:
  print("Não foram encontrados outliers no DataFrame.")
else:
  print(f"Total de outliers encontrados: {total_outliers}")
  for col, count in outliers_dict.items():
    if count > 0:
      print(f"  * Coluna '{col}': {count} outliers")

"""**CONSTRUINDO O(S) MODELO(S)**"""

basef = base

basef.head()

# Salvando o DataFrame em um arquivo CSV
#basef.to_csv('basef.csv')

X = basef.drop(columns=['Situação no Curso'], axis=1)
X.info()

y = basef['Situação no Curso']
print(y)

print("Tipo de dados de X_train:", type(X))
print("Tipo de dados de y_train:", type(y))
print("Formato de X_train:", X.shape)
print("Formato de y_train:", y.shape)
#X = X.values
#y = y.values
y = np.array(y, dtype=int)

print(y)

# treinando os dados
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)
print(y_train)

dtree = DecisionTreeClassifier(random_state=0)

dtree.fit(X_train,y_train)

y_predTree = dtree.predict(X_test)
print("Accuracy :",round(accuracy_score(y_test,y_predTree)*100,2),"%")

"""**TESTANDO COM INSERÇÃO DE DADOS**"""

import pickle #do professor: exporta modelo ml
labels_names = basef['Situação no Curso']
pickle.dump(labels_names, open('names.pkl','wb'))
nomesbase = pickle.load(open('names.pkl','rb'))
print(nomesbase)

# Acessando a importância das variáveis
importances = dtree.feature_importances_

# Imprimindo as variáveis mais importantes do modelo
sorted_idx = importances.argsort()[::-1]
print("Variáveis mais Importantes, em ordem descrecente:")
for i in range(7):
    print(f"{X.columns[sorted_idx[i]]}: {importances[sorted_idx[i]]}")

basef.head(20)

"""ESCOLHENDO ATRIBUTOS por inferencia: (Trabalhos relacionados analisados sugerem que variaveis explicativas de cunho socil, economico e desempenho podem ser relavantes ao modelo). Adaptando a ideia para os dados utilizados do IFSULDEMINAS Campus Machado


DICIONÁRIO DE DADOS

Estado civil: Nao Solteiro = 0/Solteiro = 1
Sexo: 'F' = 0, 'M' = 1
Etnia/Raca: nao bca = 0, bca = 1
Acesso a internet: Tenho acesso no computador em minha própria casa = 1, outros = 0
Tipo origem: nao privada = 0, privada = 1
Forma ingresso:
//
 "Ampla concorrência": 1,
  "Ampla concorrência (ENEM)": 1,
  "Ampla concorrência (SISU)": 1,
  "Ampla concorrência (Vestibular)": 1,
  demais considerar 0
//
Situação no curso: Target:(nao evade = 0 (Matriculado, Concluido, Formado), evade = 1)
I.R.A notas variando de 0 - 10
Frequência no Período: 0-100
Necessidade de auxilio estudantil:(Consigo me manter independentemente de auxílios da instituição = 0, ou seja, não preciso de auxilio/ Nao consigo me manter, preciso de auxilio ou outros correlatos = 1)
//

Carga horaria de seminario pendente: Sim:1 Nao:0
Carga horaria de Pratica profissional pendente: Sim:1 Nao:0

"""

pickle.dump(dtree, open('model.pkl','wb'))
model = pickle.load(open('model.pkl','rb'))


print (model.predict([ [1,	1,	0,	1,	0,	0,	0	] ]))#0 Nao evade
print (model.predict([ [0,	0,	0,	1,	1,	0,	0] ]))#0 Nao evade
print (model.predict([ [0,	0,	1,	1,	0,	0,	1	] ]))#1 Evade
print (model.predict([ [0,	1,	0,	1,	0,	0,	0] ]))#1 Evade
print (model.predict([ [1,	0,	1,	1,	0,	1,	1	] ]))#1 Evade